{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1dEmip3Rss6zU4RONn382"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g6Z7ec3gmr8P","executionInfo":{"status":"ok","timestamp":1759990556260,"user_tz":-330,"elapsed":17174,"user":{"displayName":"MANDURU LEELA VENKATA CHARAN,CSE(2022) Vel Tech, Chennai","userId":"13325136633223656406"}},"outputId":"aa2e8771-c558-4358-8c88-bb3666b92063"},"outputs":[{"output_type":"stream","name":"stdout","text":["Nouns: ['Web', 'example', 'web', 'page', 'text', 'parts', 'speech', 'example', 'cat', 'dog', 'verb', 'prepositions']\n","Verbs: ['contains', 'jumps', 'contains']\n","Adjectives: ['various', 'lazy']\n","Entities: []\n"]}],"source":["from bs4 import BeautifulSoup\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","def pos_tag_and_extract_info(text):\n","    doc = nlp(text)\n","    nouns = []\n","    verbs = []\n","    adjectives = []\n","    entities = []\n","    for token in doc:\n","        if token.pos_ == \"NOUN\":\n","            nouns.append(token.text)\n","        elif token.pos_ == \"VERB\":\n","            verbs.append(token.text)\n","        elif token.pos_ == \"ADJ\":\n","            adjectives.append(token.text)\n","    for entity in doc.ents:\n","        entities.append((entity.text, entity.label_))\n","    return nouns, verbs, adjectives, entities\n","web_document = \"\"\"\n","<html>\n","<head>\n","<title>Example Web Page</title>\n","</head>\n","<body>\n","<p>This is an example web page. It contains some text with various parts of speech.</p>\n","<p>For example, \"The cat jumps over the lazy dog\" contains a noun, a verb, and prepositions.</p>\n","</body>\n","</html>\n","\"\"\"\n","def extract_text_from_html(html):\n","    soup = BeautifulSoup(html, 'html.parser')\n","    return soup.get_text()\n","text_content = extract_text_from_html(web_document)\n","nouns, verbs, adjectives, entities = pos_tag_and_extract_info(text_content)\n","print(\"Nouns:\", nouns)\n","print(\"Verbs:\", verbs)\n","print(\"Adjectives:\", adjectives)\n","print(\"Entities:\", entities)"]}]}